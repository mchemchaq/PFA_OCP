///// interface /////
# import streamlit as st
# import pandas as pd
# from free_contract_extractor import FreeContractExtractor
# import tempfile
# import os

# def main():
#     st.set_page_config(
#         page_title="Free Contract Extractor",
#         page_icon="ðŸ“„",
#         layout="wide"
#     )
    
#     st.title("ðŸ“„ Free Contract Information Extractor")
#     st.markdown("**100% Free** - No API keys required! Extract contract information using pattern matching.")
    
#     # Sidebar with instructions
#     with st.sidebar:
#         st.header("ðŸ“‹ Instructions")
#         st.markdown("""
#         1. Upload your PDF contract
#         2. Click 'Extract Information'
#         3. View the extracted data
#         4. Download results as CSV
        
#         **Supported Languages:**
#         - French âœ…
#         - English âœ…
        
#         **Extracted Information:**
#         - Contract Number
#         - Supplier/Provider
#         - Client
#         - Contract Object
#         - Total Amount
#         - Currency
#         - Date
#         - Location
#         """)
    
#     # File upload
#     uploaded_file = st.file_uploader(
#         "Choose a PDF contract file",
#         type="pdf",
#         help="Upload your contract in PDF format"
#     )
    
#     if uploaded_file is not None:
#         # Save uploaded file temporarily
#         with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
#             tmp_file.write(uploaded_file.getvalue())
#             tmp_file_path = tmp_file.name
        
#         # Display file info
#         st.success(f"âœ… File uploaded: {uploaded_file.name}")
        
#         # Extract button
#         if st.button("ðŸ” Extract Contract Information", type="primary"):
#             with st.spinner("Extracting information from contract..."):
#                 try:
#                     extractor = FreeContractExtractor()
#                     result = extractor.extract_to_dict(tmp_file_path)
                    
#                     # Display results
#                     st.header("ðŸ“Š Extracted Information")
                    
#                     # Create two columns
#                     col1, col2 = st.columns(2)
                    
#                     with col1:
#                         st.subheader("Contract Details")
#                         st.write(f"**Contract Number:** {result['Contract Number'] or 'Not found'}")
#                         st.write(f"**Client:** {result['Client'] or 'Not found'}")
#                         st.write(f"**Supplier:** {result['Supplier'] or 'Not found'}")
#                         st.write(f"**Date:** {result['Date'] or 'Not found'}")
                    
#                     with col2:
#                         st.subheader("Financial & Location")
#                         st.write(f"**Total Amount:** {result['Total Amount'] or 'Not found'}")
#                         st.write(f"**Currency:** {result['Currency'] or 'Not found'}")
#                         st.write(f"**Location:** {result['Location'] or 'Not found'}")
                    
#                     # Contract object (full width)
#                     st.subheader("Contract Object")
#                     st.write(result['Object'] or 'Not found')
                    
#                     # Results table
#                     st.subheader("ðŸ“‹ Complete Results Table")
#                     df = pd.DataFrame([result])
#                     st.dataframe(df, use_container_width=True)
                    
#                     # Download button
#                     csv = df.to_csv(index=False)
#                     st.download_button(
#                         label="ðŸ“¥ Download Results as CSV",
#                         data=csv,
#                         file_name=f"contract_info_{uploaded_file.name}.csv",
#                         mime="text/csv"
#                     )
                    
#                 except Exception as e:
#                     st.error(f"âŒ Error processing file: {str(e)}")
        
#         # Clean up temporary file
#         try:
#             os.unlink(tmp_file_path)
#         except:
#             pass
    
#     # Footer
#     st.markdown("---")
#     st.markdown("ðŸ†“ **Completely Free** - No API costs, no subscriptions!")

# if __name__ == "__main__":
#     main()

////////////// extracter ///////
# import pdfplumber
# import re
# import json
# from typing import Dict, List, Optional
# from dataclasses import dataclass
# import streamlit as st
# import pandas as pd

# @dataclass
# class ContractInfo:
#     contract_number: Optional[str] = None
#     supplier: Optional[str] = None
#     client: Optional[str] = None
#     object: Optional[str] = None
#     total_amount: Optional[str] = None
#     currency: Optional[str] = None
#     date: Optional[str] = None
#     location: Optional[str] = None

# class FreeContractExtractor:
#     def __init__(self):
#         # French contract patterns
#         self.patterns = {
#             'contract_number': [
#                 r'CONTRAT\s+N[Â°Âº]\s*([A-Z0-9/\-]+)',
#                 r'Contract\s+N[Â°Âº]\s*([A-Z0-9/\-]+)',
#                 r'Contrat\s+n[Â°Âº]\s*([A-Z0-9/\-]+)',
#                 r'N[Â°Âº]\s*de\s+contrat\s*:?\s*([A-Z0-9/\-]+)',
#             ],
#             'supplier': [
#                 r'PRESTATAIRE[:\s]*([A-Z\s&]+?)(?:\n|,|\s{2,})',
#                 r'Fournisseur[:\s]*([A-Z\s&]+?)(?:\n|,|\s{2,})',
#                 r'ET\s+([A-Z\s&]+?)\s+POUR',
#                 r'sociÃ©tÃ©\s+([A-Z\s&]+?)(?:\n|,)',
#             ],
#             'client': [
#                 r'CLIENT[:\s]*([A-Z\s&\.]+?)(?:\n|,|\s{2,})',
#                 r'OCP\s+S\.?A\.?',
#                 r'ENTRE\s+([A-Z\s&\.]+?)\s+ET',
#             ],
#             'object': [
#                 r'POUR\s+(.*?)(?:\n\n|\d{4})',
#                 r'OBJET[:\s]+(.*?)(?:\n\n|ARTICLE)',
#                 r'objet\s+du\s+contrat[:\s]+(.*?)(?:\n\n|ARTICLE)',
#             ],
#             'total_amount': [
#                 r'Montant\s+TTC[:\s]*([0-9\s,\.]+\s*[A-Za-z]+)',
#                 r'PRIX\s+CONTRACTUEL[:\s]*([0-9\s,\.]+\s*[A-Za-z]+)',
#                 r'([0-9\s,\.]+)\s*Dirhams?\s*TTC',
#                 r'([0-9\s,\.]+)\s*DH\s*TTC',
#                 r'Total[:\s]*([0-9\s,\.]+\s*[A-Za-z]+)',
#             ],
#             'currency': [
#                 r'(Dirhams?|DH|EUR|USD|â‚¬|\$)',
#             ],
#             'date': [
#                 r'(\d{1,2}[/\-]\d{1,2}[/\-]\d{4})',
#                 r'(\d{4}[/\-]\d{1,2}[/\-]\d{1,2})',
#                 r'le\s+(\d{1,2}\s+\w+\s+\d{4})',
#             ],
#             'location': [
#                 r'Ã \s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)',
#                 r'Site\s+de\s+([A-Z][a-z]+)',
#                 r'siÃ¨ge\s+social.*?Ã \s+([A-Z][a-z]+)',
#             ]
#         }

#     def extract_text_from_pdf(self, pdf_path: str) -> str:
#         """Extract text from PDF using pdfplumber"""
#         text = ""
#         try:
#             with pdfplumber.open(pdf_path) as pdf:
#                 for page in pdf.pages:
#                     page_text = page.extract_text()
#                     if page_text:
#                         text += page_text + "\n"
#         except Exception as e:
#             st.error(f"Error reading PDF: {str(e)}")
#             return ""
#         return text

#     def clean_text(self, text: str) -> str:
#         """Clean and normalize text"""
#         # Remove extra whitespace
#         text = re.sub(r'\s+', ' ', text)
#         # Remove special characters but keep essential punctuation
#         text = re.sub(r'[^\w\s\-.,:/Â°Âºâ‚¬$]', ' ', text)
#         return text.strip()

#     def extract_with_patterns(self, text: str, field: str) -> List[str]:
#         """Extract information using regex patterns"""
#         results = []
#         patterns = self.patterns.get(field, [])
        
#         for pattern in patterns:
#             matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
#             for match in matches:
#                 if isinstance(match, tuple):
#                     match = match[0]
#                 cleaned = self.clean_text(match).strip()
#                 if cleaned and len(cleaned) > 2:
#                     results.append(cleaned)
        
#         return list(set(results))  # Remove duplicates

#     def extract_contract_info(self, pdf_path: str) -> ContractInfo:
#         """Extract all contract information"""
#         text = self.extract_text_from_pdf(pdf_path)
#         if not text:
#             return ContractInfo()

#         info = ContractInfo()
        
#         # Extract each field
#         contract_numbers = self.extract_with_patterns(text, 'contract_number')
#         suppliers = self.extract_with_patterns(text, 'supplier')
#         clients = self.extract_with_patterns(text, 'client')
#         objects = self.extract_with_patterns(text, 'object')
#         amounts = self.extract_with_patterns(text, 'total_amount')
#         currencies = self.extract_with_patterns(text, 'currency')
#         dates = self.extract_with_patterns(text, 'date')
#         locations = self.extract_with_patterns(text, 'location')

#         # Take the best match for each field
#         info.contract_number = contract_numbers[0] if contract_numbers else None
#         info.supplier = suppliers[0] if suppliers else None
#         info.client = clients[0] if clients else None
#         info.object = objects[0] if objects else None
#         info.total_amount = amounts[0] if amounts else None
#         info.currency = currencies[0] if currencies else None
#         info.date = dates[0] if dates else None
#         info.location = locations[0] if locations else None

#         return info

#     def extract_to_dict(self, pdf_path: str) -> Dict:
#         """Extract contract info and return as dictionary"""
#         info = self.extract_contract_info(pdf_path)
#         return {
#             'Contract Number': info.contract_number,
#             'Supplier': info.supplier,
#             'Client': info.client,
#             'Object': info.object,
#             'Total Amount': info.total_amount,
#             'Currency': info.currency,
#             'Date': info.date,
#             'Location': info.location
#         }

# def main():
#     """Simple command line interface"""
#     import sys
    
#     if len(sys.argv) != 2:
#         print("Usage: python free_contract_extractor.py <pdf_file>")
#         return
    
#     pdf_file = sys.argv[1]
#     extractor = FreeContractExtractor()
    
#     print("ðŸ” Extracting contract information...")
#     result = extractor.extract_to_dict(pdf_file)
    
#     print("\nðŸ“‹ Contract Information:")
#     print("=" * 50)
#     for key, value in result.items():
#         print(f"{key}: {value or 'Not found'}")

# if __name__ == "__main__":
#     main()
# )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))
# import fitz  # PyMuPDF for PDF processing
# from PIL import Image
# import io
# import re
# from transformers import pipeline, AutoProcessor, AutoModelForDocumentQuestionAnswering
# import os

# class FreeContractExtractor:
#     def __init__(self):
#         # Initialize the Document Question Answering pipeline
#         # You can choose different models here.
#         # "impira/layoutlm-document-qa" is a good general-purpose model.
#         # "naver-clova-ix/donut-base-finetuned-doc-qa" is another option, but needs image input.

#         # For this example, we'll use a text-based QA approach with a robust model
#         # that can handle various types of questions.
#         # We will extract text first, then apply QA.
#         self.qa_pipeline = pipeline("question-answering", model="deepset/roberta-base-squad2")
#         print("Initialized deepset/roberta-base-squad2 for Question Answering.")

#         # If you want to use Donut or LayoutLMv3 directly on images,
#         # the setup would be different (processor, model, then inference).
#         # For simplicity and broad applicability without complex image handling in Streamlit,
#         # we'll stick to text-based QA after OCR.

#     def _extract_text_from_pdf(self, pdf_path):
#         """Extracts text from a PDF file."""
#         text = ""
#         try:
#             document = fitz.open(pdf_path)
#             for page_num in range(len(document)):
#                 page = document.load_page(page_num)
#                 text += page.get_text()
#             document.close()
#         except Exception as e:
#             print(f"Error extracting text from PDF: {e}")
#             raise
#         return text

#     def _ask_question(self, context, question):
#         """Asks a question to the QA model and returns the answer."""
#         if not context.strip():
#             return None
#         try:
#             # The QA model has a context limit (e.g., 512 tokens for roberta-base-squad2).
#             # For very long documents, we might need to chunk the text or implement
#             # a more sophisticated retrieval system. For now, we'll pass the whole text.
#             # If the answer is not found in the initial context, it might be due to this limit.
#             result = self.qa_pipeline(question=question, context=context)
#             # The model returns a dictionary with 'score', 'start', 'end', 'answer'
#             # We are interested in 'answer'
#             if result and result['score'] > 0.5:  # Consider answers with reasonable confidence
#                 return result['answer'].strip()
#             return None
#         except Exception as e:
#             print(f"Error asking question '{question}': {e}")
#             return None

#     def extract_to_dict(self, pdf_path):
#         """
#         Extracts key information from a contract PDF using AI Question Answering.
#         Returns a dictionary with extracted fields.
#         """
#         extracted_data = {
#             "Contract Number": None,
#             "Supplier": None,
#             "Client": None,
#             "Object": None,
#             "Total Amount": None,
#             "Currency": None,
#             "Date": None,
#             "Location": None,
#         }

#         try:
#             full_text = self._extract_text_from_pdf(pdf_path)
#             print(f"texxt ==========> {full_text}")
#             if not full_text:
#                 raise ValueError("Could not extract any text from the PDF.")

#             # Define questions for each piece of information
#             questions = {
#                 "Contract Number": "What is the contract number?",
#                 "Supplier": "Who is the supplier or provider?",
#                 "Client": "Who is the client or customer?",
#                 "Object": "What is the object or purpose of the contract?",
#                 "Total Amount": "What is the total amount?",
#                 "Currency": "What is the currency of the contract?",
#                 "Date": "What is the contract date or effective date?",
#                 "Location": "Where was the contract signed or the location mentioned?",
#             }

#             # Ask each question and populate the dictionary
#             for key, question in questions.items():
#                 answer = self._ask_question(full_text, question)
#                 if answer:
#                     extracted_data[key] = answer
#                     print(f"Extracted {key}: {answer}")
#                 else:
#                     print(f"Could not extract {key} using QA.")

#             # Post-processing for amount and currency if needed
#             if extracted_data["Total Amount"]:
#                 # Try to clean up amount (remove commas, ensure it's a number)
#                 amount_str = extracted_data["Total Amount"].replace(",", "")
#                 # Use regex to find a number in the string
#                 match = re.search(r'\d[\d\s.,]*', amount_str)
#                 if match:
#                     extracted_data["Total Amount"] = match.group(0).strip()

#             if extracted_data["Currency"] and len(extracted_data["Currency"]) > 5:
#                 # If currency answer is too long, try to find common currency symbols/codes
#                 currency_match = re.search(r'\$|â‚¬|Â£|Â¥|USD|EUR|GBP|CAD|AUD', extracted_data["Currency"], re.IGNORECASE)
#                 if currency_match:
#                     extracted_data["Currency"] = currency_match.group(0).upper()


#         except Exception as e:
#             print(f"An error occurred during AI extraction: {e}")
#             # Fallback to pattern matching if AI fails or desired
#             # (You could re-integrate your original regex logic here as a fallback)
#             # For this example, we'll let the error propagate if no text is found.
#             pass

#         return extracted_data

# # Example of how to use (for local testing)
# if __name__ == "__main__":
#     # Create a dummy PDF for testing
#     from reportlab.lib.pagesizes import letter
#     from reportlab.pdfgen import canvas

#     def create_dummy_pdf(filename="dummy_contract.pdf"):
#         c = canvas.Canvas(filename, pagesize=letter)
#         c.drawString(100, 750, "Contract Number: C-2023-001")
#         c.drawString(100, 730, "This contract is made between:")
#         c.drawString(100, 710, "Supplier: AI Solutions Inc.")
#         c.drawString(100, 690, "Client: Global Enterprises Ltd.")
#         c.drawString(100, 670, "Object: Provision of AI Consulting Services for 12 months.")
#         c.drawString(100, 650, "Total Amount: 1,500,000 EUR")
#         c.drawString(100, 630, "Date: January 15, 2023")
#         c.drawString(100, 610, "Location: Paris, France")
#         c.save()
#         print(f"Created dummy PDF: {filename}")
#         return filename

#     dummy_pdf = create_dummy_pdf()

#     extractor = FreeContractExtractor()
#     extracted_info = extractor.extract_to_dict(dummy_pdf)
#     print("\nExtracted Information:")
#     for key, value in extracted_info.items():
#         print(f"{key}: {value}")

#     os.remove(dummy_pdf) # Clean up
# ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////